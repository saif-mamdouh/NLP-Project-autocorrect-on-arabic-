{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95El_cTPkjDp",
        "outputId": "f2075824-4490-42cf-fc2f-e68952a18718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xPH4xgqnYvb",
        "outputId": "8c28d6e9-cf29-459e-f338-fa885c999b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcNH1BCozEoO",
        "outputId": "bafce42d-ba44-4c99-c504-b6a6c5b15c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from pyarabic) (1.17.0)\n",
            "Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/126.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n"
          ]
        }
      ],
      "source": [
        "!pip install pyarabic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtILRn3-zNSd",
        "outputId": "6d7a8cea-55af-48e9-e7d4-2ac59eeb991e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OPa0OXntnJDz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForMaskedLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dooeJHCRnpYL"
      },
      "outputs": [],
      "source": [
        "# Initialize model and tokenizer\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"/content/my_model\")\n",
        "    model = AutoModelForMaskedLM.from_pretrained(\"/content/my_model\")\n",
        "    print(\"Loaded fine-tuned model from /content/my_model\")\n",
        "except:\n",
        "    print(\"Using pretrained model\")\n",
        "    model_name = \"UBC-NLP/MARBERT\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpinlmwsFG86"
      },
      "outputs": [],
      "source": [
        "# Move model to correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMcxHYhZ8a3n"
      },
      "source": [
        "# **Data preprocessing functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6_cXS6VoROp"
      },
      "outputs": [],
      "source": [
        "def preprocess(sentence: str) -> str:\n",
        "    \"\"\"Enhanced Arabic text preprocessing with additional normalization\"\"\"\n",
        "    sentence = sentence.replace('أ', 'ا').replace('إ', 'ا').replace('آ', 'ا')\n",
        "    sentence = re.sub(r'[^\\u0600-\\u06FF\\s]', '', sentence)  # Keep only Arabic characters and spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence).strip()  # Clean up extra spaces\n",
        "    return sentence\n",
        "\n",
        "\n",
        "def data_vocab(dataframe, min_freq=3):\n",
        "    \"\"\"Create vocabulary with frequency filtering\"\"\"\n",
        "    words_freq = Counter()\n",
        "    for text in dataframe['text']:\n",
        "        words_freq.update(text.split())\n",
        "    return {word: freq for word, freq in words_freq.items() if freq >= min_freq}\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenization function for dataset\"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev7llNDl-rVU"
      },
      "source": [
        "# **Prediction functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjDDIi0a-GKs"
      },
      "outputs": [],
      "source": [
        "def normalize_hamza(word: str) -> str:\n",
        "    # Normalize common Hamza variants to unify them\n",
        "    word = word.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"ؤ\", \"و\").replace(\"ئ\", \"ي\").replace(\"ء\", \"\")\n",
        "    return word\n",
        "\n",
        "def find_misspellings(text: str, vocab: dict, threshold: float = 0.28) -> list:\n",
        "    \"\"\"Identify potentially misspelled words using MLM probability and additional context\"\"\"\n",
        "    words = text.split()\n",
        "    misspelled_indices = []\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word not in vocab and normalize_hamza(word) not in vocab:  # Word not in vocab (may be misspelled)\n",
        "            masked_words = words.copy()\n",
        "            masked_words[i] = tokenizer.mask_token\n",
        "            masked_sentence = \" \".join(masked_words)\n",
        "\n",
        "            inputs = tokenizer(masked_sentence, return_tensors=\"pt\").to(device)\n",
        "            mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits[0, mask_token_index]\n",
        "                probs = torch.softmax(logits, dim=-1).squeeze()\n",
        "                word_id = tokenizer.encode(word, add_special_tokens=False)\n",
        "                word_prob = torch.mean(probs[word_id]) if word_id else 0\n",
        "\n",
        "            # Use lower threshold to catch more potential errors\n",
        "            if word_prob < threshold:\n",
        "                misspelled_indices.append(i)\n",
        "\n",
        "    return misspelled_indices\n",
        "\n",
        "\n",
        "def generate_masked_sentences(text: str, misspelled_indices: list) -> list:\n",
        "    \"\"\"Generate masked sentences for each misspelled word\"\"\"\n",
        "    words = text.split()\n",
        "    return [\n",
        "        \" \".join(words[:idx] + [tokenizer.mask_token] + words[idx + 1:])\n",
        "        for idx in misspelled_indices\n",
        "    ]\n",
        "\n",
        "\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "\n",
        "def predict(masked_sentence: str, top_k=25) -> list:\n",
        "    \"\"\"Predict top-k masked words from MLM\"\"\"\n",
        "    inputs = tokenizer(masked_sentence, return_tensors=\"pt\").to(device)\n",
        "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits[0, mask_token_index]\n",
        "    probs = torch.softmax(logits, dim=-1).squeeze()\n",
        "    top_k_tokens = torch.topk(probs, top_k)\n",
        "\n",
        "    predictions = []\n",
        "    for token_id in top_k_tokens.indices:\n",
        "        token = tokenizer.decode([token_id]).strip()\n",
        "        # نتاكد إن الكلمة عربية ولها طول معقول\n",
        "        if re.match(r'^[\\u0600-\\u06FF]{2,}$', token):\n",
        "            predictions.append(token)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N1WPUSPFiam",
        "outputId": "ebceeba7-bedb-4c6f-e373-43dcee5f8933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ✅ وززارة [MASK] والتعليم → ['التربية', 'التربيه', 'للتربية', 'الصحه', 'الصحة', 'والتربية', 'النقل', 'بالتربية', 'طيب', 'بالصحه', 'تربيه', 'والصحه', 'تربية', 'انا', 'طب', 'المعلم', 'الانتساب', 'المدرسه', 'المعلمين', 'التعليم', 'التعلم', 'المناهج', 'قياس', 'بالصحة'] (Expected: التربية)\n",
            "Model ✅ يوم [MASK] → ['جميل', 'الجمعه', 'ميلادي', 'الخميس', 'مميز', 'الجمعة', 'حلو', 'لطيف', 'الاحد', 'سعيد', 'جمييل', 'جديد', 'السبت', 'التلات', 'عظيم', 'المعلم', 'الثلاثاء', 'الاربعاء', 'تاريخي', 'العظماء', 'حافل', 'عالمي', 'خميس', 'العلم'] (Expected: السبت)\n",
            "Model ✅ الطقس اليوم [MASK] → ['جميل', 'حلو', 'بارد', 'رايع', 'لطيف', 'حار', 'خرافي', 'غايم', 'مختلف', 'امطار', 'رووعه', 'هه', 'ربيعي', 'حر', 'غبار', 'حلوو', 'جمييل', 'ممتاز', 'روعه', 'ضباب', 'رووعة', 'ماطر'] (Expected: حر)\n",
            "Model ✅ اللغة [MASK] صعبة → ['العربية', 'الانجليزية', 'الفرنسية', 'الالمانية', 'صارت', 'الاسبانية', 'الصينية', 'الفارسية', 'التركية', 'العربيه', 'الايطالية', 'جدا', 'الروسية', 'بقت', 'مرة', 'الفصحى', 'عندك', 'العالمية', 'دي', 'عندهم', 'احيانا', 'المصرية', 'الكردية', 'اللبنانية', 'طلعت'] (Expected: العربية)\n",
            "Model ✅ ذهب محمد إلى [MASK] → ['الجحيم', 'الله', 'المستشفى', 'ربه', 'جهنم', 'النوم', 'الجنة', 'المسجد', 'القبر', 'الصلاة', 'النار', 'السماء', 'منزله', 'الجنه', 'السجن', 'المدرسة', 'قبره', 'القمر', 'جده', 'كربلاء', 'محمد', 'مصر', 'الموت', 'لندن'] (Expected: المدرسة)\n",
            "Model ✅ أنا أحب [MASK] في المساء → ['القهوة', 'القهوه', 'السهر', 'النوم', 'البحر', 'صوتك', 'الصباح', 'قهوتي', 'تويتر', 'اجلس', 'الدوام', 'الهدوء', 'اللعب', 'المطر', 'الرقص', 'الليل', 'انام', 'الشاي', 'اسهر', 'السفر', 'المشي', 'الغروب', 'اخرج', 'اسمعها', 'اشوفك'] (Expected: اللعب)\n",
            "Model ❌ السيارة [MASK] في الطريق → ['واقفة', 'تسير', 'متوقفة', 'اللي', 'تمشي', 'واقفه', 'وقفت', 'الثانية', 'الي', 'تنتظرك', 'الان', 'شغالة', 'كلها', 'زحمة', 'تنتظرني', 'الجديدة', 'تعطلت', 'مازالت', 'راحت', 'ضاعت', 'مفتوحة', 'ماشية', 'توقف', 'فاضية', 'قافلة'] (Expected: سريعة)\n",
            "Model ✅ كرة [MASK] هي المفضلة لدي → ['القدم', 'اليد', 'السلة', 'قدم', 'الطايرة', 'الماء', 'السله', 'التنس', 'الثلج', 'ميسي', 'الطاولة', 'سلة', 'الهاتريك', 'يد', 'المطر', 'الدجاج', 'الذهبية', 'الظهر', 'الابطال', 'الطايره', 'الارجنتين', 'برشلونة', 'الامارات', 'الصالات'] (Expected: القدم)\n"
          ]
        }
      ],
      "source": [
        "test_cases = [\n",
        "    (\"وززارة [MASK] والتعليم\", \"التربية\"),\n",
        "    (\"يوم [MASK]\", \"السبت\"),\n",
        "    (\"الطقس اليوم [MASK]\", \"حر\"),\n",
        "    (\"اللغة [MASK] صعبة\", \"العربية\"),\n",
        "    (\"ذهب محمد إلى [MASK]\", \"المدرسة\"),\n",
        "    (\"أنا أحب [MASK] في المساء\", \"اللعب\"),\n",
        "    (\"السيارة [MASK] في الطريق\", \"سريعة\"),\n",
        "    (\"كرة [MASK] هي المفضلة لدي\", \"القدم\")\n",
        "]\n",
        "\n",
        "for sentence, expected in test_cases:\n",
        "    preds = predict(sentence)\n",
        "    is_correct = expected in preds\n",
        "    print(f\"Model {'✅' if is_correct else '❌'} {sentence} → {preds} (Expected: {expected})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf4FO_fm-xuU"
      },
      "source": [
        "# **Pipeline function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4s0ZH1X83c_"
      },
      "outputs": [],
      "source": [
        "def pipeline(input_text: str, vocab: dict, verbose: bool = True) -> str:\n",
        "    processed_text = preprocess(input_text)\n",
        "    vocab = data_vocab(df, min_freq=3)\n",
        "    misspelled_indices = find_misspellings(processed_text, vocab)\n",
        "\n",
        "    if not misspelled_indices:\n",
        "        if verbose:\n",
        "            print(\"✅ لا توجد أخطاء إملائية واضحة.\")\n",
        "        return processed_text\n",
        "\n",
        "    masked_sentences = generate_masked_sentences(processed_text, misspelled_indices)\n",
        "    words = processed_text.split()\n",
        "    corrections = {}\n",
        "\n",
        "    for idx, masked in zip(misspelled_indices, masked_sentences):\n",
        "        original_word = words[idx]\n",
        "        candidates = predict(masked)\n",
        "        if candidates:\n",
        "            best_candidate = min(candidates, key=lambda c: levenshtein_distance(c, original_word))\n",
        "            corrections[original_word] = best_candidate\n",
        "            words[idx] = best_candidate\n",
        "\n",
        "    corrected_sentence = \" \".join(words)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"🔍 الكلمات التي تم تصحيحها:\")\n",
        "        for original, corrected in corrections.items():\n",
        "            print(f\" - {original} ➤ {corrected}\")\n",
        "\n",
        "    return corrected_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_zlKGTc9B_n",
        "outputId": "0dfe7226-aea9-434d-81dd-ce394fe5bfba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  target\n",
            "0  بين أستوديوهات ورزازات وصحراء مرزوكة وآثار ولي...       0\n",
            "1  قررت النجمة الأمريكية أوبرا وينفري ألا يقتصر ع...       0\n",
            "2  أخبارنا المغربية الوزاني تصوير الشملالي ألهب ا...       0\n",
            "3  اخبارنا المغربية قال ابراهيم الراشدي محامي سعد...       0\n",
            "4  تزال صناعة الجلود في المغرب تتبع الطريقة التقل...       0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the .txt file as if it's a CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/arabic_dataset_classifiction.txt', encoding='utf-8')\n",
        "\n",
        "# Optional: Fix column name if needed\n",
        "df.columns = ['text', 'target']\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkCrU4NwoTSC"
      },
      "outputs": [],
      "source": [
        "# Clean dataset\n",
        "df = df.drop(columns=['targe'], errors='ignore').dropna().drop_duplicates()\n",
        "df['text'] = df['text'].apply(preprocess)\n",
        "df['text'] = df['text'].apply(lambda x: x if len(x.split()) > 5 else None)\n",
        "df = df.dropna().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8gOxOLG9K_m"
      },
      "outputs": [],
      "source": [
        "# Create vocabulary\n",
        "words_freq = data_vocab(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a6685aebe8204834b878d145828e5c3f",
            "2fbd04f25696401db5c16c3c4621759a",
            "531d266653b245ec9988ea19eeb393f8",
            "2bc15f7210c141aabfd495a6760b07a7",
            "66b872f4f2bb4960b48f1b58abceb94d",
            "3c6b179b2eca43d78acc2d67633d8b3a",
            "18727913e7234c73985d864f0c61800a",
            "54a0d3e6758b48a7b7c17b24603bc47d",
            "8e9bdc49b57a4d97b52428b7f201ff3b",
            "9063ffa00fdb4235adfeb31faee865ac",
            "6c828f340c494cd78a9e83b0ab813288"
          ]
        },
        "id": "hkkI6xeq9MnN",
        "outputId": "adf52fd6-8e42-4704-df3b-63fac69cdc68"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6685aebe8204834b878d145828e5c3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Prepare Hugging Face dataset\n",
        "dataset = Dataset.from_pandas(df[:10000])  # Use smaller subset for training\n",
        "dataset = dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "dataset = dataset.train_test_split(test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgjqpGnqshgK"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,\n",
        "    logging_steps=100,\n",
        "    optim=\"adamw_torch\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtrH1Um59Ttt",
        "outputId": "16451a95-df15-4f3d-ed92-7ce3fe90a00d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-328daa5726ac>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Optional: Use a smaller subset for faster testing\n",
        "train_subset = dataset[\"train\"].select(range(1000))\n",
        "test_subset = dataset[\"test\"].select(range(200))\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_subset,\n",
        "    eval_dataset=test_subset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "PoBzBDr0pF6x",
        "outputId": "2ab8b0e3-8b64-4543-b0d8-13553a7e866e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myahiahanii45\u001b[0m (\u001b[33myahiahanii45-helwan-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250513_031735-65yxfajj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yahiahanii45-helwan-university/huggingface/runs/65yxfajj' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/yahiahanii45-helwan-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yahiahanii45-helwan-university/huggingface' target=\"_blank\">https://wandb.ai/yahiahanii45-helwan-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yahiahanii45-helwan-university/huggingface/runs/65yxfajj' target=\"_blank\">https://wandb.ai/yahiahanii45-helwan-university/huggingface/runs/65yxfajj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train and save model\n",
        "trainer.train()\n",
        "trainer.save_model(\"/content/my_model\")\n",
        "tokenizer.save_pretrained(\"/content/my_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bVSNodCA1oP",
        "outputId": "703ba325-9fbd-479b-ce74-bfecb6007b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - وززارة ➤ وزارة\n",
            " - النربية ➤ التربية\n",
            " - تعطبل ➤ تعطيل\n",
            " - السسبت ➤ السبت\n",
            " - الحالييه ➤ الحاليه\n",
            " - المعلمون ➤ المعلمين\n",
            " - الططلاب ➤ الطلاب\n",
            "Incorrect Sentence: وززارة النربية والتعليم تعلن عن تعطبل الدراسة رسميا يوم السسبت نظرا للظروف الجوية الحالييه وحفاظا على سلامة المعلمون و الططلاب\n",
            "Corrected Sentence: وزارة التربية والتعليم تعلن عن تعطيل الدراسة رسميا يوم السبت نظرا للظروف الجوية الحاليه وحفاظا على سلامة المعلمين و الطلاب\n",
            "--------------------\n",
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - الفنسي ➤ الفرنسي\n",
            " - الحميس ➤ الخميس\n",
            " - القتتل ➤ القتل\n",
            "Incorrect Sentence: بعد أن قرر القضاء الفنسي الإبقاء على المغني المغربي سعد لمجرد الذي قبض عليه يوم الحميس بتهمتي القتتل و التحرش\n",
            "Corrected Sentence: بعد ان قرر القضاء الفرنسي الابقاء على المغني المغربي سعد لمجرد الذي قبض عليه يوم الخميس بتهمتي القتل و التحرش\n",
            "--------------------\n",
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - الاسلاميه ➤ الاسلاميه\n",
            " - حربب ➤ خراب\n",
            "Incorrect Sentence: قال الفنان المغربي محمد الخياري نحن احرار الامه الاسلاميه و لن نسمح بحدوث حربب في الوطن\n",
            "Corrected Sentence: قال الفنان المغربي محمد الخياري نحن احرار الامه الاسلاميه و لن نسمح بحدوث خراب في الوطن\n",
            "--------------------\n",
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - يذههبون ➤ يذهبون\n",
            " - المدرسه ➤ المدرسه\n",
            " - الباككر ➤ الباكر\n",
            "Incorrect Sentence: الطلاب يذههبون الى المدرسه في الصباح الباككر لتلقي الدروس\n",
            "Corrected Sentence: الطلاب يذهبون الى المدرسه في الصباح الباكر لتلقي الدروس\n",
            "--------------------\n",
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - القاهر ➤ القاهرة\n",
            "Incorrect Sentence: وصل الريس الى القاهر صباح اليوم لعقد اجتماع مهم مع الوزراء\n",
            "Corrected Sentence: وصل الريس الى القاهرة صباح اليوم لعقد اجتماع مهم مع الوزراء\n",
            "--------------------\n",
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - المايه ➤ المياه\n",
            "Incorrect Sentence: يعاني المزارعون من مشاكل في توفر المايه للري في فصل الصيف\n",
            "Corrected Sentence: يعاني المزارعون من مشاكل في توفر المياه للري في فصل الصيف\n",
            "--------------------\n",
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - مداوله ➤ منافسه\n",
            " - طويله ➤ جلسه\n",
            " - المحكمه ➤ المحكمه\n",
            "Incorrect Sentence: اصدر القاضي حكمه النهائي بعد مداوله طويله بين اعضاء المحكمه\n",
            "Corrected Sentence: اصدر القاضي حكمه النهائي بعد منافسه جلسه بين اعضاء المحكمه\n",
            "--------------------\n",
            "🔍 الكلمات التي تم تصحيحها:\n",
            " - مهمه ➤ مهمه\n",
            " - المؤهله ➤ الموهلة\n",
            " - العاللم ➤ العالم\n",
            "Incorrect Sentence: المنتخب الوطني يخض مباراة مهمه في التصفيات المؤهله لكأس العاللم\n",
            "Corrected Sentence: المنتخب الوطني يخض مباراة مهمه في التصفيات الموهلة لكاس العالم\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "input_texts = [\n",
        "    \"وززارة النربية والتعليم تعلن عن تعطبل الدراسة رسميا يوم السسبت نظرا للظروف الجوية الحالييه وحفاظا على سلامة المعلمون و الططلاب\",\n",
        "    \"بعد أن قرر القضاء الفنسي الإبقاء على المغني المغربي سعد لمجرد الذي قبض عليه يوم الحميس بتهمتي القتتل و التحرش\",\n",
        "    \"قال الفنان المغربي محمد الخياري نحن احرار الامه الاسلاميه و لن نسمح بحدوث حربب في الوطن\",\n",
        "    \"الطلاب يذههبون الى المدرسه في الصباح الباككر لتلقي الدروس\",\n",
        "    \"وصل الريس الى القاهر صباح اليوم لعقد اجتماع مهم مع الوزراء\",\n",
        "    \"يعاني المزارعون من مشاكل في توفر المايه للري في فصل الصيف\",\n",
        "    \"اصدر القاضي حكمه النهائي بعد مداوله طويله بين اعضاء المحكمه\",\n",
        "    \"المنتخب الوطني يخض مباراة مهمه في التصفيات المؤهله لكأس العاللم\",\n",
        "]\n",
        "\n",
        "for input_text in input_texts:\n",
        "    # Pass words_freq as the vocab argument\n",
        "    true_sentence = pipeline(input_text, words_freq)\n",
        "    print('Incorrect Sentence:', input_text)\n",
        "    print('Corrected Sentence:', true_sentence)\n",
        "    print('-' * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIPiSYZQOMm5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Define test dataset with ground-truth corrections\n",
        "test_df = pd.DataFrame({\n",
        "    'incorrect': input_texts,\n",
        "    'correct': [\n",
        "        \"وزارة التربية والتعليم تعلن عن تعطيل الدراسة رسميا يوم السبت نظرا للظروف الجوية الحالية وحفاظا على سلامة المعلمون و الطلاب\",\n",
        "        \"بعد ان قرر القضاء الفرنسي الابقاء على المغني المغربي سعد لمجرد الذي قبض عليه يوم الخميس بتهمتي القتل و التحرش\",\n",
        "        \"قال الفنان المغربي محمد الخياري نحن احرار الامه الاسلامية و لن نسمح بحدوث حرب في الوطن\",\n",
        "        \"الطلاب يذهبون الى المدرسة في الصباح الباكر لتلقي الدروس\",\n",
        "        \"وصل الريس الى القاهرة صباح اليوم لعقد اجتماع مهم مع الوزراء\",\n",
        "        \"يعاني المزارعون من مشاكل في توفر الماء للري في فصل الصيف\",\n",
        "        \"اصدر القاضي حكمه النهائي بعد مداولة طويلة بين اعضاء المحكمة\",\n",
        "        \"المنتخب الوطني يخوض مباراة مهمة في التصفيات المؤهلة لكاس العالم\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "def evaluate_pipeline(test_df, pipeline_func, df):\n",
        "    y_true_words = []\n",
        "    y_pred_words = []\n",
        "    sentence_correct = []\n",
        "\n",
        "    for idx, row in test_df.iterrows():\n",
        "        incorrect = row['incorrect']\n",
        "        true_sentence = row['correct']\n",
        "\n",
        "        # Run pipeline\n",
        "        pred_sentence = pipeline_func(incorrect, df, verbose=False)\n",
        "\n",
        "        # Split sentences into words\n",
        "        true_words = true_sentence.split()\n",
        "        pred_words = pred_sentence.split()\n",
        "        incorrect_words = incorrect.split()\n",
        "\n",
        "        # Ensure same length for comparison\n",
        "        min_len = min(len(true_words), len(pred_words), len(incorrect_words))\n",
        "        true_words = true_words[:min_len]\n",
        "        pred_words = pred_words[:min_len]\n",
        "        incorrect_words = incorrect_words[:min_len]\n",
        "\n",
        "        # Word-level comparison for misspelled words\n",
        "        for i in range(min_len):\n",
        "            if incorrect_words[i] != true_words[i]:  # Misspelled word\n",
        "                y_true_words.append(true_words[i])\n",
        "                y_pred_words.append(pred_words[i])\n",
        "\n",
        "        # Sentence-level accuracy\n",
        "        sentence_correct.append(true_sentence == pred_sentence)\n",
        "\n",
        "    # Calculate metrics\n",
        "    word_accuracy = accuracy_score(y_true_words, y_pred_words)\n",
        "    word_f1 = f1_score(y_true_words, y_pred_words, average='weighted', zero_division=0)\n",
        "    conf_matrix = confusion_matrix(y_true_words, y_pred_words)\n",
        "    sentence_accuracy = np.mean(sentence_correct)\n",
        "\n",
        "    return {\n",
        "        'word_accuracy': word_accuracy,\n",
        "        'word_f1': word_f1,\n",
        "        'confusion_matrix': conf_matrix,\n",
        "        'sentence_accuracy': sentence_accuracy,\n",
        "        'y_true_words': y_true_words,\n",
        "        'y_pred_words': y_pred_words\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrIwkkwFOljL",
        "outputId": "1fca0a14-0d47-4f4a-cf3a-dfb384ba59ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluation Section ===\n",
            "Evaluation Results:\n",
            "Word-Level Accuracy: 0.5769\n",
            "Word-Level F1 Score: 0.5769\n",
            "Sentence-Level Accuracy: 0.2500\n",
            "Confusion Matrix (Word-Level):\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Detailed Errors:\n",
            "True: الحالية, Predicted: الحاليه\n",
            "True: الاسلامية, Predicted: الاسلاميه\n",
            "True: حرب, Predicted: خراب\n",
            "True: المدرسة, Predicted: المدرسه\n",
            "True: الماء, Predicted: المياه\n",
            "True: مداولة, Predicted: منافسه\n",
            "True: طويلة, Predicted: جلسه\n",
            "True: المحكمة, Predicted: المحكمه\n",
            "True: يخوض, Predicted: يخض\n",
            "True: مهمة, Predicted: مهمه\n",
            "True: المؤهلة, Predicted: الموهلة\n"
          ]
        }
      ],
      "source": [
        "# Evaluation Section\n",
        "print(\"\\n=== Evaluation Section ===\")\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluate_pipeline(test_df, pipeline, df)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"Evaluation Results:\")\n",
        "print(f\"Word-Level Accuracy: {results['word_accuracy']:.4f}\")\n",
        "print(f\"Word-Level F1 Score: {results['word_f1']:.4f}\")\n",
        "print(f\"Sentence-Level Accuracy: {results['sentence_accuracy']:.4f}\")\n",
        "print(\"Confusion Matrix (Word-Level):\")\n",
        "print(results['confusion_matrix'])\n",
        "print(\"\\nDetailed Errors:\")\n",
        "for true, pred in zip(results['y_true_words'], results['y_pred_words']):\n",
        "    if true != pred:\n",
        "        print(f\"True: {true}, Predicted: {pred}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "WXTxJoTv4eAi",
        "outputId": "57f07953-5ac9-48a9-90a3-937a456657bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/my_model/ (stored 0%)\n",
            "  adding: content/my_model/special_tokens_map.json (deflated 14%)\n",
            "  adding: content/my_model/vocab.txt (deflated 61%)\n",
            "  adding: content/my_model/tokenizer_config.json (deflated 14%)\n",
            "  adding: content/my_model/model.safetensors (deflated 14%)\n",
            "  adding: content/my_model/training_args.bin (deflated 15%)\n",
            "  adding: content/my_model/config.json (deflated 13%)\n",
            "  adding: content/my_model/tokenizer.json (deflated 14%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_44a4f6cf-25e1-4143-8cbf-068269838346\", \"my_model.zip\", 428221)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r my_model.zip /content/my_model\n",
        "files.download('my_model.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWGqj9GDXUyA",
        "outputId": "31832ecf-71c9-4a99-a9ac-0985d294c4ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: Levenshtein==0.27.1 in /usr/local/lib/python3.11/dist-packages (from python-Levenshtein) (0.27.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio transformers torch pandas python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "sLW2jS_sXZg8",
        "outputId": "0335afbf-f177-4c18-e6c2-cb7eb372d357"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at asafaya/bert-base-arabic were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://10a41491113f6caf97.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://10a41491113f6caf97.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "\n",
        "# ==== Load model ====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"/content/my_model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"asafaya/bert-base-arabic\").to(device)\n",
        "model.eval()\n",
        "\n",
        "# Read the .txt file as if it's a CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/arabic_dataset_classifiction.txt', encoding='utf-8')\n",
        "\n",
        "# Optional: Fix column name if needed\n",
        "df.columns = ['text', 'target']\n",
        "\n",
        "\n",
        "def preprocess(sentence: str) -> str:\n",
        "    sentence = sentence.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"آ\", \"ا\")\n",
        "    sentence = re.sub(r\"[^\\u0600-\\u06FF\\s]\", \"\", sentence)\n",
        "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
        "    return sentence\n",
        "\n",
        "def data_vocab(dataframe, min_freq=3):\n",
        "    words_freq = Counter()\n",
        "    for text in dataframe[\"text\"]:\n",
        "        words_freq.update(text.split())\n",
        "    return {word: freq for word, freq in words_freq.items() if freq >= min_freq}\n",
        "\n",
        "def normalize_hamza(word: str) -> str:\n",
        "    return (\n",
        "        word.replace(\"أ\", \"ا\")\n",
        "        .replace(\"إ\", \"ا\")\n",
        "        .replace(\"ؤ\", \"و\")\n",
        "        .replace(\"ئ\", \"ي\")\n",
        "        .replace(\"ء\", \"\")\n",
        "    )\n",
        "\n",
        "def find_misspellings(text: str, vocab: dict, threshold: float = 0.28) -> list:\n",
        "    words = text.split()\n",
        "    misspelled_indices = []\n",
        "    for i, word in enumerate(words):\n",
        "        if word not in vocab and normalize_hamza(word) not in vocab:\n",
        "            masked_words = words.copy()\n",
        "            masked_words[i] = tokenizer.mask_token\n",
        "            masked_sentence = \" \".join(masked_words)\n",
        "            inputs = tokenizer(masked_sentence, return_tensors=\"pt\").to(device)\n",
        "            mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits[0, mask_token_index]\n",
        "                probs = torch.softmax(logits, dim=-1).squeeze()\n",
        "                word_id = tokenizer.encode(word, add_special_tokens=False)\n",
        "                word_prob = torch.mean(probs[word_id]) if word_id else 0\n",
        "            if word_prob < threshold:\n",
        "                misspelled_indices.append(i)\n",
        "    return misspelled_indices\n",
        "\n",
        "def generate_masked_sentences(text: str, misspelled_indices: list) -> list:\n",
        "    words = text.split()\n",
        "    return [\n",
        "        \" \".join(words[:idx] + [tokenizer.mask_token] + words[idx + 1:])\n",
        "        for idx in misspelled_indices\n",
        "    ]\n",
        "\n",
        "def predict(masked_sentence: str, top_k=25) -> list:\n",
        "    inputs = tokenizer(masked_sentence, return_tensors=\"pt\").to(device)\n",
        "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits[0, mask_token_index]\n",
        "    probs = torch.softmax(logits, dim=-1).squeeze()\n",
        "    top_k_tokens = torch.topk(probs, top_k)\n",
        "    predictions = []\n",
        "    for token_id in top_k_tokens.indices:\n",
        "        token = tokenizer.decode([token_id]).strip()\n",
        "        if re.match(r\"^[\\u0600-\\u06FF]{2,}$\", token):\n",
        "            predictions.append(token)\n",
        "    return predictions\n",
        "\n",
        "def pipeline(input_text: str, vocab: dict) -> str:\n",
        "    processed_text = preprocess(input_text)\n",
        "    misspelled_indices = find_misspellings(processed_text, vocab)\n",
        "\n",
        "    if not misspelled_indices:\n",
        "        return f\"✅ لا توجد أخطاء إملائية:\\n\\n{processed_text}\"\n",
        "\n",
        "    masked_sentences = generate_masked_sentences(processed_text, misspelled_indices)\n",
        "    words = processed_text.split()\n",
        "    corrections = {}\n",
        "\n",
        "    for idx, masked in zip(misspelled_indices, masked_sentences):\n",
        "        original_word = words[idx]\n",
        "        candidates = predict(masked)\n",
        "        if candidates:\n",
        "            best_candidate = min(candidates, key=lambda c: levenshtein_distance(c, original_word))\n",
        "            corrections[original_word] = best_candidate\n",
        "            words[idx] = best_candidate\n",
        "\n",
        "    corrected_sentence = \" \".join(words)\n",
        "    corrections_text = \"🔍 الكلمات التي تم تصحيحها:\\n\"\n",
        "    for original, corrected_word in corrections.items():\n",
        "        corrections_text += f\" - {original} ➤ {corrected_word}\\n\"\n",
        "\n",
        "    return f\"❌ قبل التصحيح:\\n{input_text}\\n\\n✅ بعد التصحيح:\\n{corrected_sentence}\\n\\n{corrections_text}\"\n",
        "\n",
        "# Prepare vocab\n",
        "df = df.drop(columns=[\"targe\"], errors=\"ignore\").dropna().drop_duplicates()\n",
        "df[\"text\"] = df[\"text\"].apply(preprocess)\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: x if len(x.split()) > 5 else None)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "words_freq = data_vocab(df)\n",
        "\n",
        "# ==== Gradio Interface ====\n",
        "gr.Interface(\n",
        "    fn=lambda x: pipeline(x, words_freq),\n",
        "    inputs=gr.Textbox(lines=5, label=\"أدخل النص\"),\n",
        "    outputs=gr.Textbox(label=\"النص المصحح\"),\n",
        "    title=\"تصحيح الأخطاء الإملائية للنصوص العربية\",\n",
        "    description=\"أدخل جملة باللغة العربية وسنقوم بمحاولة تصحيح الأخطاء الإملائية.\"\n",
        ").launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18727913e7234c73985d864f0c61800a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc15f7210c141aabfd495a6760b07a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9063ffa00fdb4235adfeb31faee865ac",
            "placeholder": "​",
            "style": "IPY_MODEL_6c828f340c494cd78a9e83b0ab813288",
            "value": " 10000/10000 [00:22&lt;00:00, 437.41 examples/s]"
          }
        },
        "2fbd04f25696401db5c16c3c4621759a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c6b179b2eca43d78acc2d67633d8b3a",
            "placeholder": "​",
            "style": "IPY_MODEL_18727913e7234c73985d864f0c61800a",
            "value": "Map: 100%"
          }
        },
        "3c6b179b2eca43d78acc2d67633d8b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "531d266653b245ec9988ea19eeb393f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54a0d3e6758b48a7b7c17b24603bc47d",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e9bdc49b57a4d97b52428b7f201ff3b",
            "value": 10000
          }
        },
        "54a0d3e6758b48a7b7c17b24603bc47d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b872f4f2bb4960b48f1b58abceb94d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c828f340c494cd78a9e83b0ab813288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e9bdc49b57a4d97b52428b7f201ff3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9063ffa00fdb4235adfeb31faee865ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6685aebe8204834b878d145828e5c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fbd04f25696401db5c16c3c4621759a",
              "IPY_MODEL_531d266653b245ec9988ea19eeb393f8",
              "IPY_MODEL_2bc15f7210c141aabfd495a6760b07a7"
            ],
            "layout": "IPY_MODEL_66b872f4f2bb4960b48f1b58abceb94d"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}